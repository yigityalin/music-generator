{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2bc356d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "PROJECT_DIR = Path().resolve()\n",
    "DATA_DIR = PROJECT_DIR / \"data\"\n",
    "\n",
    "DATA_DOWNLOAD_ROOT = \"https://github.com/czhuang/JSB-Chorales-dataset/raw/master/\"\n",
    "DATA_FILENAME = \"Jsb16thSeparated.npz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3634215",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "DATA_FILEPATH = keras.utils.get_file(\n",
    "    DATA_FILENAME,\n",
    "    DATA_DOWNLOAD_ROOT + DATA_FILENAME,\n",
    "    cache_subdir=DATA_DIR\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73f52e55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bool(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e65428a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import namedtuple\n",
    "\n",
    "def load_data(path=DATA_FILEPATH):\n",
    "    with np.load(DATA_FILEPATH, \"r\", allow_pickle=True, encoding=\"latin1\") as datasets:\n",
    "        Dataset = namedtuple(\"Dataset\", dir(datasets.f))\n",
    "        data = {\n",
    "            dataset: getattr(datasets.f, dataset)\n",
    "            for dataset in dir(datasets.f)\n",
    "        }\n",
    "    return Dataset(**data)\n",
    "\n",
    "data = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d32058b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0.0, 36.0, 37.0, 38.0, 39.0, 40.0, 41.0, 42.0, 43.0, 44.0, 45.0, 46.0, 47.0, 48.0, 49.0, 50.0, 51.0, 52.0, 53.0, 54.0, 55.0, 56.0, 57.0, 58.0, 59.0, 60.0, 61.0, 62.0, 63.0, 64.0, 65.0, 66.0, 67.0, 68.0, 69.0, 70.0, 71.0, 72.0, 73.0, 74.0, 75.0, 76.0, 77.0, 78.0, 79.0, 80.0, 81.0}\n"
     ]
    }
   ],
   "source": [
    "unique_notes = set()\n",
    "for dataset in [\"train\", \"valid\", \"test\"]:\n",
    "    for chorale in getattr(data, dataset):\n",
    "        chorale[np.isnan(chorale)] = 0.0\n",
    "        for chord in chorale:\n",
    "            for note in chord:\n",
    "                unique_notes.add(note)\n",
    "print(unique_notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ac9fec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "import pretty_midi\n",
    "from pretty_midi import PrettyMIDI, Instrument, Note\n",
    "\n",
    "def play_chorale(chorale, tempo=120, sample_rate=44100):\n",
    "    note_duration = 60 / tempo\n",
    "    midi = PrettyMIDI()\n",
    "    instrument = pretty_midi.instrument_name_to_program(\"Acoustic Grand Piano\")\n",
    "    midi.instruments.append(Instrument(instrument))\n",
    "    \n",
    "    note_time = 0.0\n",
    "    note_velocity = 100\n",
    "    for chord in chorale:\n",
    "        for note in chord:\n",
    "            midi.instruments[0].notes.append(\n",
    "                Note(note_velocity, note, note_time, note_time + note_duration),\n",
    "            )\n",
    "        note_time += note_duration\n",
    "        \n",
    "    return display(Audio(midi.synthesize(), rate=sample_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92efe6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# play_chorale(data.train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8de58e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_label(data):\n",
    "    X = data[:-1]\n",
    "    Y = data[1:]\n",
    "    return X, Y\n",
    "\n",
    "def create_windows(data, window_size, window_shift, drop_remainder=True):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(data)\n",
    "    dataset = dataset.window(window_size + 1, window_shift, drop_remainder=drop_remainder)\n",
    "    return dataset.flat_map(lambda data: data.batch(window_size + 1))\n",
    "\n",
    "def flatten_data(data):\n",
    "    return tf.reshape(data, [-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "969821f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(data, batch_size=32, window_size=32, window_shift=8,\n",
    "                   preprocessing_function=None, shuffle_buffer_size=8,\n",
    "                   cache=False, prefetch=None):\n",
    "    data = tf.ragged.constant(data, ragged_rank=1)\n",
    "    data = tf.cast(data, dtype=tf.float32)\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(data)\n",
    "    dataset = dataset.map(flatten_data)\n",
    "    dataset = dataset.flat_map(lambda data: create_windows(data, window_size, window_shift))\n",
    "    if preprocessing_function:\n",
    "        dataset = dataset.map(preprocessing_function)\n",
    "    dataset = dataset.map(create_label)\n",
    "    if shuffle_buffer_size:\n",
    "        dataset = dataset.shuffle(shuffle_buffer_size)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    if cache:\n",
    "        dataset = dataset.cache()\n",
    "    if prefetch:\n",
    "        dataset = dataset.prefetch()\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "03072093",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(data, normalize=False):\n",
    "    def set_notes_range(note):\n",
    "        if note == 0:\n",
    "            return 0.0\n",
    "        return note - min(unique_notes - {0.0}) + 1\n",
    "    data = tf.map_fn(set_notes_range, data)\n",
    "    if normalize:\n",
    "        data = (data - tf.math.reduce_mean(data)) / tf.math.reduce_std(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "73856d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = create_dataset(data.train, preprocessing_function=preprocess)\n",
    "valid_data = create_dataset(data.valid, preprocessing_function=preprocess)\n",
    "test_data = create_dataset(data.test, preprocessing_function=preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "613c2680",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "class Conv1D_BN(layers.Layer):\n",
    "    def __init__(self, filters, kernel_size=4, strides=1,\n",
    "                 padding=\"causal\", dilation_rate=1,\n",
    "                 activation=\"relu\", batch_norm=True, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.filters = filters\n",
    "        self.kernel_size = kernel_size\n",
    "        self.strides = strides\n",
    "        self.padding = padding\n",
    "        self.dilation_rate = dilation_rate\n",
    "        self.activation = keras.activations.get(activation)\n",
    "        self.batch_norm = batch_norm\n",
    "        self.layers = [\n",
    "            layers.Conv1D(filters, kernel_size, strides, padding, dilation_rate=dilation_rate, activation=activation),\n",
    "        ]\n",
    "        if self.batch_norm:\n",
    "            self.layers.append(layers.BatchNormalization())\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        Z = inputs\n",
    "        for layer in self.layers:\n",
    "            Z = layer(Z)\n",
    "        return Z\n",
    "    \n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {\n",
    "            **base_config,\n",
    "            \"filters\": self.filters,\n",
    "            \"kernel_size\": self.kernel_size,\n",
    "            \"strides\": self.strides,\n",
    "            \"padding\": self.padding,\n",
    "            \"dilation_rate\": self.dilation_rate,\n",
    "            \"activation\": self.activation,\n",
    "            \"batch_norm\": self.batch_norm,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6458bb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_tuner as kt\n",
    "\n",
    "def create_model(hp):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(layers.Embedding(input_dim=len(unique_notes), output_dim=8, input_shape=[None]))\n",
    "    model.add(Conv1D_BN(32, dilation_rate=1))\n",
    "    model.add(Conv1D_BN(48, dilation_rate=2))\n",
    "    model.add(Conv1D_BN(64, dilation_rate=4))\n",
    "    model.add(Conv1D_BN(96, dilation_rate=8))\n",
    "    model.add(Conv1D_BN(128, dilation_rate=16))\n",
    "    model.add(Conv1D_BN(196, dilation_rate=32))\n",
    "    \n",
    "    dropout_rate = hp.Float('dropout_rate', min_value=0.2, max_value=0.5, default=0.35)\n",
    "    model.add(layers.LSTM(256, return_sequences=True, recurrent_dropout=dropout_rate))\n",
    "    model.add(layers.LSTM(512, return_sequences=True, recurrent_dropout=dropout_rate))\n",
    "    model.add(layers.Dense(len(unique_notes), activation=keras.activations.softmax))\n",
    "              \n",
    "    loss = keras.losses.SparseCategoricalCrossentropy()\n",
    "    optimizer = keras.optimizers.Nadam(learning_rate=1e-3)\n",
    "    metrics = [keras.metrics.SparseCategoricalAccuracy()]\n",
    "    model.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n",
    "              \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9024248c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tuner = kt.BayesianOptimization(create_model,\n",
    "#                                 objective='val_sparse_categorical_accuracy',\n",
    "#                                 max_trials=10,\n",
    "#                                 directory='tuner-logs',\n",
    "#                                 project_name='bayesian-optimization')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7038d950",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# tuner.search(train_data, epochs=30, validation_data=valid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1f93577a",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = PROJECT_DIR / \"models\" / \"model.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1f31c314",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = tuner.get_best_models(num_models=1)[0]\n",
    "# model.save(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "26a8f318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.load_model(MODEL_PATH,\n",
    "                                custom_objects={\n",
    "                                    \"Conv1D_BN\": Conv1D_BN\n",
    "                                })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b3048314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "286/286 [==============================] - 13s 39ms/step - loss: 0.7183 - sparse_categorical_accuracy: 0.7940\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7183104753494263, 0.7939797043800354]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2e330404",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_and_choose(model, chords, num_options, scale_logits):\n",
    "    predictions = model.predict(chords)[0, -1:]\n",
    "    logits = tf.math.log(predictions) / scale_logits\n",
    "    if num_options is None:\n",
    "        return tf.cast(tf.random.categorical(logits, num_samples=1), tf.float32)\n",
    "    top_notes = np.flip(np.argsort(logits))[..., :num_options]\n",
    "    highest_logits = np.take(logits, top_notes)\n",
    "    note_index = tf.random.categorical(highest_logits, num_samples=1)\n",
    "    return top_notes[0, note_index]\n",
    "\n",
    "def generate_chorale(model, initial_chords, length, num_options=None, scale_logits=1):\n",
    "    notes = tf.constant(initial_chords, dtype=tf.float32)\n",
    "    notes = tf.map_fn(preprocess, notes)\n",
    "    notes = tf.reshape(notes, [1, -1])\n",
    "    for chord in range(length):\n",
    "        for note in range(4):\n",
    "            note = predict_and_choose(model, notes, num_options, scale_logits)\n",
    "            notes = tf.concat([notes, note], axis=1)\n",
    "    notes = tf.where(notes == 0, notes, notes + min(unique_notes - {0.0}) - 1)\n",
    "    return tf.reshape(notes, shape=[-1, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c75329ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "chorales = [\n",
    "    generate_chorale(model, initial_chords=chorale[:8], length=40, scale_logits=1.8)\n",
    "    for chorale in data.test[:5]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "82f0d707",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for chorale in chorales:\n",
    "#     play_chorale(chorale)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
